---
title: "[Deep Learning] CNN (Convolutional Neural Network)"
excerpt: "컴퓨터 비전의 핵심 기술, CNN의 원리와 특징에 대해 알아보자"

tags:
  - python
  - AI engineering
  - deep learning
  - CNN
  - computer vision

toc: true
toc_sticky: true

date: 2025-07-29
last_modified_at: 2025-07-29
categories: 
  - deeplearning
---

## CNN (Convolutional Neural Network)이란?

**CNN**은 주로 이미지 인식과 같은 **컴퓨터 비전 분야**의 데이터를 분석하기 위해 사용되는 인공 신경망의 한 종류입니다. 핵심은 **합성곱(Convolution) 연산**을 사용한다는 점입니다.

> **핵심 아이디어**: 이미지의 공간적 구조를 보존하면서 효율적으로 특징을 추출하는 것

---

## 컴퓨터는 이미지를 어떻게 볼까?

### 흑백 이미지
- **단일 채널** 사용
- 각 픽셀은 **0~255 범위**의 하나의 값만 가짐
- 명암의 정도를 나타냄

### 컬러 이미지  
- **RGB 3개 채널** 사용
- 각 채널은 **0~255 값**을 가짐
- 세 채널의 조합으로 다양한 색상 표현

```
예시: 224×224 컬러 이미지
- 입력 형태: (224, 224, 3)
- 총 픽셀 수: 224 × 224 × 3 = 150,528개 값
```

---

## FCN (Fully Connected Network)의 한계

전통적인 FCN으로 이미지를 처리할 때 발생하는 문제들:

- **파라미터 수의 폭발적 증가** → 과적합 위험 및 계산 비용 증가
- **확장성 부족** → 대용량 이미지 처리의 어려움
- **인접 픽셀 관계 반영 불가** → 공간적 정보 손실
- **1차원 벡터 변환** → 패턴 학습의 어려움

> **문제점**: 224×224 이미지를 FCN으로 처리하면 첫 번째 레이어만 해도 150,528개의 가중치가 필요!

---

## 사람은 어떻게 이미지를 인식하는가?

### 고양이 뉴런 실험 (Hubel & Wiesel, 1959)
- 특정 뉴런이 **수직, 수평, 대각선**에 각각 반응하는 것을 관측
- **전체 뉴런이 아닌 특정 뉴런**이 활성화되는 현상 발견
- 각 뉴런의 **전문화된 역할** 존재 확인

### CNN의 계층적 인식 과정
1. **1단계**: 선과 같은 **단순한 특징** 잡아내기
2. **2단계**: 모서리, 경계선 등 **중간 복잡도 특징** 학습
3. **3단계**: 부분과 전체를 연결하는 **복잡한 특징** 인식

> **인간의 시각 인식과 유사**: 단순한 요소부터 복잡한 패턴까지 점진적 학습

---

## CNN의 역사

### LeNet-5 (1998)
- **얀 르쿤(Yann LeCun)**에 의해 개발
- CNN의 **최초 구현 모델**
- 손글씨 인식에 혁신적인 성과 달성


## CNN의 핵심 특징

### 1. 부분 연결 (Local Connectivity)
- 전체 이미지를 한 번에 분석하지 않음
- **작은 지역부터 점진적 학습**
- FCN과 차별화되는 핵심 특징

### 2. 가중치 공유 (Weight Sharing)
- **동일한 필터**를 이미지 전체에 적용
- 파라미터 수 대폭 감소
- **계산 효율성 향상**

### 3. 계층적 특성 (Hierarchical Feature Learning)
- **하위 레이어**: 단순한 특징 (선, 모서리)
- **상위 레이어**: 복잡한 특징 (얼굴, 객체)
- 점진적으로 추상화된 특징 학습

> **핵심**: 지역적 패턴 → 전역적 패턴으로의 점진적 학습

---

## 합성곱 연산의 핵심 요소

### 1. 커널 (Kernel) / 필터 (Filter)
- **커널 사이즈**: CNN에서 사용하는 필터 행렬의 크기
- 일반적으로 3×3, 5×5, 7×7 등의 크기 사용
- 작은 커널: 세밀한 특징 추출
- 큰 커널: 넓은 영역의 특징 포착

```
커널 크기별 특징:
- 3×3: 세밀한 특징, 계산 효율적
- 5×5: 중간 수준 특징
- 7×7: 넓은 영역 특징, 계산 비용 높음
```

### 2. 스트라이드 (Stride)
- 합성곱 필터의 **이동 간격**
- 몇 칸씩 이동할지 설정하는 것 (보통 1이나 2로 설정)
- **스트라이드가 커지면 출력 맵의 크기는 작아짐**

#### 스트라이드의 특징
- 합성곱 연산의 복잡도를 줄임
- 너무 큰 스트라이드는 정보 누락의 위험
- 스트라이드로 건너뛰더라도 아예 무시하는 픽셀은 없음

### 3. 패딩 (Padding)
- 가장자리일수록 특성에 반영되는 횟수가 적은 특징을 이용
- 입력 데이터 가장자리에 0이나 다른 값을 추가하여 크기를 확장하는 과정

#### 패딩의 목적
- 연산 시 이미지 가장자리 정보 손실 방지
- 출력 크기 조정

#### 패딩의 종류

**Valid Padding**
- 패딩을 사용하지 않음 (no padding)
- 출력 크기 줄어듦
- 계산량 감소
- 가장자리 연산 참여 횟수가 적어 가장자리 정보 손실 위험
- 간단한 특징 학습에 유리

**Same Padding**
- 출력 맵의 크기와 입력 맵의 크기가 같아지도록 필요한 만큼 패딩 추가
- CNN 모델에서 가장 널리 사용

**Full Padding**
- 출력 크기가 입력 맵보다 커지도록 충분한 패딩 추가
- 더 넓은 영역을 학습할 때 사용

---

## 합성곱 레이어 (Convolutional Layer) 상세 분석

### 합성곱 연산의 수학적 특성

#### 1. 선형성 (Linearity)
- **합성곱 연산은 선형적**입니다
- 입력값과 필터값의 **선형 조합**만 포함
- 수학적으로: `f(x + y) = f(x) + f(y)`, `f(ax) = af(x)` 성질 만족

#### 2. 비선형성 추가의 필요성
- **합성곱 연산 후 활성화 함수를 적용**하여 비선형성을 추가
- **ReLU 함수**가 가장 인기 있고 널리 사용됨
- 비선형성을 추가하지 않으면 **선형 변환에 불과**하여 복잡한 데이터 패턴을 학습할 수 없음

> **핵심**: 선형 연산 + 비선형 활성화 함수 = 강력한 특징 추출 능력

### 출력 맵 크기 계산 공식

```
출력 맵 크기 = (입력 크기 - 필터 크기 + 2 × 패딩) / 스트라이드 + 1
```

#### 계산 예시
- **입력**: 32×32 이미지
- **필터**: 3×3 커널
- **패딩**: 1 (Same padding)
- **스트라이드**: 1

```
출력 크기 = (32 - 3 + 2 × 1) / 1 + 1 = 32
```

### 활성화 함수의 역할

#### 1. ReLU (Rectified Linear Unit)
- **가장 널리 사용**되는 활성화 함수
- **계산 효율적**: `f(x) = max(0, x)`
- **기울기 소실 문제 완화**
- **희소성(sparsity) 유도**

#### 2. 기타 활성화 함수
- **Sigmoid**: 이진 분류에서 출력층에 사용
- **Softmax**: 다중 분류에서 출력층에 사용
- **Leaky ReLU**: ReLU의 개선 버전

---

## CNN의 주요 레이어

### 1. 합성곱 레이어 (Convolutional Layer)
- 합성곱 연산 수행
- **목적**: 특징 추출
- **출력**: 특징 맵 (Feature Map)
- 선형적이며 입력값과 필터값의 선형조합만 포함됨. 
- 컨볼루션 연산후에 활성화 함수(인기있는 렐루 함수를 보통 사용) 를 적용해서 비선형성을 추가함
- 비선형성을 추가하지 않으면 선형변환에 불가해 복잡한 데이터 패턴을 학습할수 없게 만듦 

### 2. 풀링 레이어 (Pooling Layer)
- **목적**: 맵의 차원을  축소하여 계산량 감소
- 이미지에서 중요한 정보만 뽑아내고, 필요없는 정보는 버려서 이미지 크기를 줄이는 과정
- **종류**: Max Pooling, Average Pooling, Min Pooling
- **장점**: 과적합 방지, 계산 효율성 향상
- **주의**: 공간적 정밀도가 필요한 작업에서는 신중하게 사용 

### 3. 플라튼 레이어 (Flatten Layer)
- **핵심**: 맵을 1차원 벡터로 변환하는 레이어
- **목적**: CNN에서 주로 사용되며 FCL과의 연결을 위해 필요 
- 입력맵-> Flatten Layer-> FCL


### 4. Fully Connected Layer
- **목적**: 최종 분류나 회귀를 위한 출력을 생성
- 일반적으로 CNN의 마지막 부분에 위치(컨볼루션 레이어와 풀링 레이어 이후) 
- 컨볼루션 레이어에서 추출된 공간적 특징을 전역적으로 결합
- **주의**: 과적합의 위험 (드랍아웃 Dropout 등의 정규화 기법 사용),입력의 공간적 구조를 무시 (컨볼루션과
다르게 공간적 관계가 고려되지 않음)
- **대체기법** : 일부 모델에서는 Global Average PoolingGAP 사용


 레이어 적용방법 예시: 
 CONV(활성화함수포함)(1~3회반복) -> pooling (해상도에 따라 2-5회 정도 반복) -> Flatten ->FC(1-3회 반복) ->Softmax 
---





